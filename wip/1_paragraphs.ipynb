{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_text(prompt):\n",
    "    url = 'http://host.docker.internal:11434/api/generate'\n",
    "    data = {\n",
    "      \"model\": \"mistral\",\n",
    "      \"prompt\": \"Instruct: \" + prompt + \"\\nOutput:\",\n",
    "      \"options\": {\n",
    "        \"stop\": [\"Instruct:\", \"Output:\"]\n",
    "      },\n",
    "      \"raw\": True,\n",
    "      \"stream\": False\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, json=data)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for key, value in response_json.items():\n",
    "# #     print(f\"{key}: {value}\")\n",
    "# response_json = generate_text(\"write a very short essay about the moon\")\n",
    "# print(\"\\n\".join(textwrap.wrap(response_json[\"response\"], width=80)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stinson lay still in the sand where he fell, gloating over the success\n",
      "of his arrival.\n"
     ]
    }
   ],
   "source": [
    "def parse_into_paragraphs(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "        paragraphs = content.split('\\n\\n')  # Splitting on two newlines to get paragraphs\n",
    "    return paragraphs\n",
    "\n",
    "# Usage\n",
    "file_path = '../data/thegodnextdoor.txt'\n",
    "paragraphs = parse_into_paragraphs(file_path)\n",
    "\n",
    "start_paragraph = 20\n",
    "\n",
    "print(paragraphs[start_paragraph])\n",
    "\n",
    "# for i, paragraph in enumerate(paragraphs):\n",
    "#     print(f\"Paragraph {i+1}:\\n{paragraph}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = paragraphs[start_paragraph]\n",
    "para = para.replace('\\n', ' ').strip()  # Added strip() to remove leading and trailing whitespace\n",
    "\n",
    "\n",
    "instructions = \"\"\"\n",
    "### Instructions for Generating a Detailed Prompt from a Sci-Fi Novel Sentence\n",
    "Given a paragraph from a science fiction novel, generate a detailed prompt for creating similar text. First, analyze the paragraph to extract key elements such as the main character(s), setting, and principal actions or events. \n",
    "Then, expand these elements by describing the character’s appearance, emotional state, and any unique sci-fi traits. Detail the setting to emphasize its sci-fi nature, whether it be a futuristic city, an alien landscape, or a space vessel. \n",
    "Discuss the action in depth, focusing on its significance and how it unfolds in the sci-fi context. \n",
    "Highlight any futuristic technology or advanced scientific concepts mentioned. Determine the tone and mood of the text, and suggest incorporating sensory details to create a vivid and immersive experience. \n",
    "Integrate all these aspects into a comprehensive prompt that captures the essence and atmosphere of the original paragraph, guiding the generation of a similar sci-fi narrative.\n",
    "\n",
    "Create a detailed prompt for generating a paragraph in the style of high-concept science fiction, focusing on elements typical of authors known for their complex narratives and richly detailed worlds. \n",
    "The text should feature morally ambiguous characters, intricate plotlines, and a setting in a vast, technologically advanced universe. \n",
    "Emphasize the creation of a multi-layered narrative, where characters navigate through a world filled with advanced technology, artificial intelligences, and sprawling cosmic environments. \n",
    "The tone should be mature, blending cerebral themes with visceral experiences, and incorporating a subtle, dark humor. \n",
    "The prompt should guide the LLM to produce text that explores ethical dilemmas, power dynamics, and the impact of technology on society, all within a deeply immersive and vividly described sci-fi setting.\n",
    "\n",
    "1. **Core Elements Identification**\n",
    "   - Break down the sentence to identify the main components: character(s), setting, action, and any notable technology or sci-fi element.\n",
    "\n",
    "2. **Descriptive Details Expansion**\n",
    "   - **Character**: Describe the character’s physical appearance, emotional state, and actions, highlighting any unique sci-fi characteristics or traits.\n",
    "   - **Setting**: Detail the environment or location, focusing on elements that emphasize the sci-fi genre, such as futuristic cities, alien planets, or advanced technology settings.\n",
    "   - **Action**: Elaborate on the central action or event described in the sentence, detailing how it unfolds and its significance in the scene.\n",
    "\n",
    "3. **Sci-Fi Elements Incorporation**\n",
    "   - Emphasize any sci-fi elements present in the sentence, such as futuristic technology, extraterrestrial life forms, or advanced scientific concepts, describing how they feature in the scene.\n",
    "\n",
    "4. **Tone and Mood Setting**\n",
    "   - Determine the sentence's tone and mood (e.g., tense, mysterious, exhilarating, somber) and use this to guide the descriptive language and atmosphere in the prompt.\n",
    "\n",
    "5. **Vivid Picture Creation**\n",
    "   - Use sensory details to create an immersive experience, describing visuals, sounds, and tactile sensations to bring the scene to life.\n",
    "\n",
    "6. **Cohesive Elements Combination**\n",
    "   - Integrate all the identified and expanded details into a cohesive and comprehensive description that captures the essence and atmosphere of the original sentence.\n",
    "\n",
    "This structured approach will help in transforming a sentence from a science fiction novel into a detailed and vivid prompt suitable for further exploration or image generation.\n",
    "\n",
    "Remember you must output only terse LLM prompt that will generate the text!\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "prompt = f\"Generate a terse prompt for an LLM that will generate the supplied text. Text is a paragraph from a sci-fi novel. **Text** \\n\\\"{para}\\\"\\nFollow these instructions:\\n{instructions}\\n \"\n",
    "#print(prompt)\n",
    "\n",
    "# response_json = generate_text(prompt)\n",
    "# print(\"\\n\".join(textwrap.wrap(response_json[\"response\"], width=80)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 21 of 30 paragraphs.\n",
      "Processed 22 of 30 paragraphs.\n",
      "Processed 23 of 30 paragraphs.\n",
      "Processed 24 of 30 paragraphs.\n",
      "Processed 25 of 30 paragraphs.\n",
      "Processed 26 of 30 paragraphs.\n",
      "Processed 27 of 30 paragraphs.\n",
      "Processed 28 of 30 paragraphs.\n",
      "Processed 29 of 30 paragraphs.\n",
      "Processed 30 of 30 paragraphs.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize DataFrame\n",
    "df = pd.DataFrame(columns=['Original Paragraph', 'Prompt'])\n",
    "process_cutoff = 10\n",
    "total_paragraphs = len(paragraphs)\n",
    "for i in range(start_paragraph, min(start_paragraph + total_paragraphs, start_paragraph + process_cutoff)):\n",
    "    paragraph = paragraphs[i]\n",
    "    prompt = f\"Generate a terse prompt for an LLM that will generate the supplied text. Text is a paragraph from a sci-fi novel. **Text** \\n\\\"{paragraph}\\\"\\nFollow these instructions:\\n{instructions}\\n \"\n",
    "\n",
    "    response_json = generate_text(prompt)\n",
    "    response = response_json[\"response\"]\n",
    "    \n",
    "    response = f\"{response.strip()}\"\n",
    "    # Append to DataFrame using pd.concat\n",
    "    new_row = pd.DataFrame({'Original Paragraph': [paragraph], 'Prompt': [response]})\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "    print(f\"Processed {i+1} of {min(start_paragraph + total_paragraphs, start_paragraph + process_cutoff)} paragraphs.\")\n",
    "    df.to_csv('output.csv', index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Paragraph    \\nStinson lay still in the sand where he fell,...\n",
      "Prompt                \"Create a sci-fi character named Stinson, lyin...\n",
      "Name: 0, dtype: object\n",
      "Prompt:\n",
      "\"Create a sci-fi character named Stinson, lying on an alien sandy surface, feeling triumphant. Detail his appearance and emotional state. Set the scene in a futuristic landscape with advanced technology nearby. Describe the action as a successful arrival or accomplishment with sci-fi connotations. Include any advanced technology or unique elements from your source text.\"\n",
      "\n",
      "Original Paragraph:\n",
      "\n",
      "Stinson lay still in the sand where he fell, gloating over the success\n",
      "of his arrival.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "print(df.iloc[0])\n",
    "record_index = 0  # Replace with the desired record index\n",
    "\n",
    "prompt = df.loc[record_index, 'Prompt']\n",
    "original_paragraph = df.loc[record_index, 'Original Paragraph']\n",
    "\n",
    "print(\"Prompt:\")\n",
    "print(prompt)\n",
    "print(\"\\nOriginal Paragraph:\")\n",
    "print(original_paragraph)\n",
    "\n",
    "# Assuming df has been properly defined and contains the columns 'input' and 'output'\n",
    "df_transposed = df.rename(columns={'Prompt': 'input', 'Original Paragraph': 'output'})\n",
    "df_filtered = df_transposed[['input', 'output']]\n",
    "df_filtered.to_json('output.jsonl', orient='records', lines=True)\n",
    "\n",
    "# Load the JSONL file\n",
    "with open('output.jsonl', 'r') as file:\n",
    "    jsonl_data = file.readlines()\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data, val_data = train_test_split(jsonl_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save the training and validation sets to separate files\n",
    "with open('train.jsonl', 'w') as file:\n",
    "    file.writelines(train_data)\n",
    "\n",
    "with open('val.jsonl', 'w') as file:\n",
    "    file.writelines(val_data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
